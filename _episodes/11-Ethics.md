---
title: "Ethics"
teaching: 8
exercises: 0
questions:
- "What ethical considerations are there when making data public?"
objectives:
- "Understand privacy, freedom, explainability, and fairness as they go into managing data ethics."
keypoints:
- "Privacy, freedom, explainability, and fairness all go into managing data ethics."

---
Technology poses ethical challenges. There are several areas of research in data ethics. This will serve as a primer for them, additional reading is included.
- Privacy
- Freedom
- Explainability
- Fairness

*Privacy* what control do people have over the data collected about them? For example, if a person has a BRCA mutation that increases their risk of cancer should their health insurer be able to increase the insurance rate of their policy?

*Freedom* do people have the freedom to share data about themselves without fear of consequences?

*Explainability* can the underlying algorithmic processes be explained or tested?

Are you or do you know anyone who believes their phone is listening to them?
- Companies who implement predictive analytics are drifting towards needing to prove the negative with regard to privacy (that they're following their privacy policies) to consumers because their predictive analytics are so good.

*Fairness* Because machine learning algorithms often find new, unexpected connections. Such algorithms are useful because they can interpret data that a human cannot; they can improve the fairness of these decisions or they can exacerbate existing biases. Ascertaining when and how machine learning systems  introduce bias into decision-making processes presents a significant new challenge in developing these tools.

"While we don’t promise equal outcomes, we have strived to deliver equal opportunity." –Barack Obama

- Humans do not entirely agree on what is fair.

Choice of Algorithmic Model Impacts the Output.
Low Impact Decision, High Volume ex. Facebook Advertising
High Impact Decision, Low Volume ex. Medical Testing

Anti-discrimination laws cover machine learning algorithms and, even if variables related to protected-class status are excluded, these algorithms can still produce disparate impacts. Such impacts can be measured if the variables that they use correlate with both the output variable and a variable for protected-class status. Even unintentional discrimination results in legal risk.

Both public and private entities should conduct disparate impact assessments. Software developers should perform disparate impact analyses before publishing or using their algorithms.

> ## Resources
> - https://www.brookings.edu/research/fairness-in-algorithmic-decision-making/

{% include links.md %}
